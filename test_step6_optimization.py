#!/usr/bin/env python3
"""
STEP 6 OPTIMIZATION TESTING SCRIPT
Comprehensive testing for all optimization features implemented in Step 6

This script tests all optimization components from yangIni.md Step 6:
1. Model optimization (quantization, pruning, ONNX export, caching)
2. Processing pipeline optimization (tracking, ROI, early exit, batch processing)
3. Resource management (webcam resolution, dynamic FPS, GPU acceleration, memory cleanup)
4. Accuracy improvements (ensemble voting, data augmentation, temporal consistency, adaptive thresholds)

Usage: python test_step6_optimization.py
"""

import os
import sys
import time
import cv2
import numpy as np
import json
import traceback
import psutil
import threading
from collections import defaultdict, deque

# Add project root to path
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Import optimization components
try:
    from src.models.optimized_cnn_model import (
        OptimizedLivenessPredictor, 
        QuantizedLivenessCNN, 
        EnsemblePredictor,
        PerformanceProfiler,
        ModelOptimizer,
        benchmark_model
    )
    OPTIMIZED_CNN_AVAILABLE = True
    print("‚úÖ Optimized CNN models available")
except ImportError as e:
    print(f"‚ùå Optimized CNN models not available: {e}")
    OPTIMIZED_CNN_AVAILABLE = False

try:
    from src.detection.optimized_landmark_detection import (
        OptimizedLivenessVerifier,
        ThreadedLivenessProcessor,
        FaceTracker,
        ROIProcessor,
        AdaptiveThresholdManager,
        MemoryManager
    )
    OPTIMIZED_DETECTION_AVAILABLE = True
    print("‚úÖ Optimized detection components available")
except ImportError as e:
    print(f"‚ùå Optimized detection components not available: {e}")
    OPTIMIZED_DETECTION_AVAILABLE = False

try:
    from src.web.app_optimized import SystemOptimizationManager, OptimizedFrameProcessor
    WEB_OPTIMIZATION_AVAILABLE = True
    print("‚úÖ Web optimization components available")
except ImportError as e:
    print(f"‚ùå Web optimization components not available: {e}")
    WEB_OPTIMIZATION_AVAILABLE = False


class OptimizationTester:
    """
    Comprehensive optimization testing suite
    """
    
    def __init__(self):
        """Initialize optimization tester"""
        self.test_results = {}
        self.performance_data = defaultdict(list)
        self.memory_usage = deque(maxlen=100)
        self.test_start_time = time.time()
        
        # Create test images
        self.test_images = self._create_test_images()
        
        print("üß™ OptimizationTester initialized")
        print(f"üìä Generated {len(self.test_images)} test images")
    
    def _create_test_images(self):
        """Create diverse test images for optimization testing"""
        test_images = []
        
        # Create images with different properties
        sizes = [(112, 112), (224, 224), (320, 240), (640, 480)]
        brightness_levels = [50, 100, 150, 200]
        noise_levels = [0, 10, 25, 50]
        
        for size in sizes:
            for brightness in brightness_levels:
                for noise in noise_levels:
                    # Generate synthetic face-like image
                    image = np.ones((size[1], size[0], 3), dtype=np.uint8) * brightness
                    
                    # Add some basic face-like features
                    cv2.circle(image, (size[0]//3, size[1]//3), size[0]//10, (brightness-20, brightness-20, brightness-20), -1)  # Left eye
                    cv2.circle(image, (2*size[0]//3, size[1]//3), size[0]//10, (brightness-20, brightness-20, brightness-20), -1)  # Right eye
                    cv2.ellipse(image, (size[0]//2, 2*size[1]//3), (size[0]//8, size[1]//12), 0, 0, 180, (brightness-30, brightness-30, brightness-30), 2)  # Mouth
                    
                    # Add noise
                    if noise > 0:
                        noise_array = np.random.normal(0, noise, image.shape).astype(np.uint8)
                        image = cv2.add(image, noise_array)
                    
                    test_images.append({
                        'image': image,
                        'properties': {
                            'size': size,
                            'brightness': brightness,
                            'noise': noise,
                            'complexity': 'synthetic_face'
                        }
                    })
        
        # Add some real-world-like variations
        for _ in range(10):
            # Random pattern images
            image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            test_images.append({
                'image': image,
                'properties': {
                    'size': (224, 224),
                    'complexity': 'random_pattern'
                }
            })
        
        return test_images
    
    def test_model_optimization(self):
        """Test model optimization features"""
        print("\n" + "="*60)
        print("üîß TESTING MODEL OPTIMIZATION")
        print("="*60)
        
        results = {}
        
        if not OPTIMIZED_CNN_AVAILABLE:
            print("‚ùå Optimized CNN models not available, skipping model optimization tests")
            return {'error': 'Optimized CNN models not available'}
        
        try:
            # Test 1: Model Size and Performance
            print("\nüìä Test 1: Model Size and Performance Comparison")
            
            # Standard model
            standard_model = OptimizedLivenessPredictor(use_quantization=False)
            
            # Quantized model
            quantized_model = OptimizedLivenessPredictor(use_quantization=True)
            
            # Benchmark both models
            test_image = self.test_images[0]['image']
            
            # Standard model benchmark
            standard_times = []
            for _ in range(20):
                start = time.time()
                _ = standard_model.predict_optimized(test_image)
                standard_times.append(time.time() - start)
            
            # Quantized model benchmark
            quantized_times = []
            for _ in range(20):
                start = time.time()
                _ = quantized_model.predict_optimized(test_image)
                quantized_times.append(time.time() - start)
            
            results['performance_comparison'] = {
                'standard_avg_time': np.mean(standard_times),
                'standard_fps': 1.0 / np.mean(standard_times),
                'quantized_avg_time': np.mean(quantized_times),
                'quantized_fps': 1.0 / np.mean(quantized_times),
                'speedup_factor': np.mean(standard_times) / np.mean(quantized_times)
            }
            
            print(f"   Standard Model: {np.mean(standard_times)*1000:.1f}ms ({1.0/np.mean(standard_times):.1f} FPS)")
            print(f"   Quantized Model: {np.mean(quantized_times)*1000:.1f}ms ({1.0/np.mean(quantized_times):.1f} FPS)")
            print(f"   Speedup: {results['performance_comparison']['speedup_factor']:.2f}x")
            
            # Test 2: Model Optimization Pipeline
            print("\n‚öôÔ∏è Test 2: Model Optimization Pipeline")
            
            try:
                optimizer = ModelOptimizer()
                base_model = OptimizedLivenessPredictor().model
                optimized_model, optimization_log = optimizer.optimize_model(base_model)
                
                results['optimization_pipeline'] = {
                    'success': True,
                    'optimizations_applied': optimization_log
                }
                
                print("   ‚úÖ Model optimization pipeline successful")
                for log_entry in optimization_log:
                    print(f"     ‚Ä¢ {log_entry}")
                    
            except Exception as e:
                results['optimization_pipeline'] = {
                    'success': False,
                    'error': str(e)
                }
                print(f"   ‚ùå Model optimization failed: {e}")
            
            # Test 3: Caching Performance
            print("\nüíæ Test 3: Caching Performance")
            
            cache_test_model = OptimizedLivenessPredictor(cache_size=50)
            
            # Test cache hits
            cache_times = []
            no_cache_times = []
            
            # First run (no cache)
            for i in range(10):
                start = time.time()
                _ = cache_test_model.predict_optimized(test_image, use_cache=False)
                no_cache_times.append(time.time() - start)
            
            # Second run (with cache)
            for i in range(10):
                start = time.time()
                _ = cache_test_model.predict_optimized(test_image, use_cache=True)
                cache_times.append(time.time() - start)
            
            cache_stats = cache_test_model.get_performance_stats()
            
            results['caching_performance'] = {
                'no_cache_avg_time': np.mean(no_cache_times),
                'cache_avg_time': np.mean(cache_times),
                'cache_speedup': np.mean(no_cache_times) / np.mean(cache_times),
                'cache_hit_ratio': cache_stats.get('cache_hit_ratio', 0),
                'cache_size': cache_stats.get('cache_size', 0)
            }
            
            print(f"   No Cache: {np.mean(no_cache_times)*1000:.1f}ms")
            print(f"   With Cache: {np.mean(cache_times)*1000:.1f}ms")
            print(f"   Cache Speedup: {results['caching_performance']['cache_speedup']:.2f}x")
            print(f"   Cache Hit Ratio: {cache_stats.get('cache_hit_ratio', 0):.2f}")
            
            # Test 4: Ensemble Voting
            print("\nüó≥Ô∏è Test 4: Ensemble Voting")
            
            try:
                models = [standard_model, quantized_model]
                weights = [0.6, 0.4]
                ensemble = EnsemblePredictor(models, weights)
                
                ensemble_times = []
                for _ in range(10):
                    start = time.time()
                    result = ensemble.predict(test_image)
                    ensemble_times.append(time.time() - start)
                
                results['ensemble_voting'] = {
                    'success': True,
                    'avg_time': np.mean(ensemble_times),
                    'fps': 1.0 / np.mean(ensemble_times),
                    'sample_result': {
                        'is_live': result['is_live'],
                        'confidence': result['confidence'],
                        'individual_confidences': result['individual_confidences']
                    }
                }
                
                print(f"   ‚úÖ Ensemble voting successful")
                print(f"   Ensemble Time: {np.mean(ensemble_times)*1000:.1f}ms ({1.0/np.mean(ensemble_times):.1f} FPS)")
                print(f"   Sample Confidence: {result['confidence']:.3f}")
                
            except Exception as e:
                results['ensemble_voting'] = {
                    'success': False,
                    'error': str(e)
                }
                print(f"   ‚ùå Ensemble voting failed: {e}")
            
        except Exception as e:
            print(f"‚ùå Model optimization testing failed: {e}")
            results['error'] = str(e)
        
        return results
    
    def test_processing_pipeline_optimization(self):
        """Test processing pipeline optimization features"""
        print("\n" + "="*60)
        print("üöÄ TESTING PROCESSING PIPELINE OPTIMIZATION")
        print("="*60)
        
        results = {}
        
        if not OPTIMIZED_DETECTION_AVAILABLE:
            print("‚ùå Optimized detection components not available, skipping pipeline tests")
            return {'error': 'Optimized detection components not available'}
        
        try:
            # Test 1: Face Tracking Performance
            print("\nüéØ Test 1: Face Tracking Performance")
            
            tracker = FaceTracker(max_tracking_frames=30)
            test_images_sequence = self.test_images[:10]  # Use first 10 images as sequence
            
            tracking_times = []
            detection_times = []
            
            for i, test_data in enumerate(test_images_sequence):
                image = test_data['image']
                
                if i == 0:
                    # Initialize tracking
                    bbox = (50, 50, 100, 100)  # Simulate face detection
                    start = time.time()
                    success = tracker.start_tracking(image, bbox)
                    tracking_times.append(time.time() - start)
                    
                    # Compare with detection time (simulation)
                    start = time.time()
                    # Simulate face detection
                    time.sleep(0.01)  # Simulate detection time
                    detection_times.append(time.time() - start)
                else:
                    # Update tracking
                    start = time.time()
                    bbox, quality = tracker.update_tracking(image)
                    tracking_times.append(time.time() - start)
                    
                    # Compare with detection time (simulation)
                    start = time.time()
                    # Simulate face detection
                    time.sleep(0.01)  # Simulate detection time
                    detection_times.append(time.time() - start)
            
            results['face_tracking'] = {
                'avg_tracking_time': np.mean(tracking_times),
                'avg_detection_time': np.mean(detection_times),
                'tracking_speedup': np.mean(detection_times) / np.mean(tracking_times),
                'tracking_success_rate': len([t for t in tracking_times if t > 0]) / len(tracking_times)
            }
            
            print(f"   Avg Tracking Time: {np.mean(tracking_times)*1000:.2f}ms")
            print(f"   Avg Detection Time: {np.mean(detection_times)*1000:.2f}ms")
            print(f"   Tracking Speedup: {results['face_tracking']['tracking_speedup']:.2f}x")
            
            # Test 2: ROI Processing
            print("\nüìê Test 2: ROI Processing Performance")
            
            roi_processor = ROIProcessor(expansion_factor=1.2)
            
            roi_times = []
            full_times = []
            
            for test_data in self.test_images[:10]:
                image = test_data['image']
                
                # Full image processing time (simulation)
                start = time.time()
                # Simulate full image processing
                processed_full = cv2.resize(image, (224, 224))
                _ = cv2.GaussianBlur(processed_full, (5, 5), 0)  # Simulate processing
                full_times.append(time.time() - start)
                
                # ROI processing time
                start = time.time()
                roi_coords = roi_processor.calculate_roi(image, (50, 50, 100, 100))
                if roi_coords:
                    roi_image = roi_processor.extract_roi(image, roi_coords)
                    if roi_image.size > 0:
                        processed_roi = cv2.resize(roi_image, (224, 224))
                        _ = cv2.GaussianBlur(processed_roi, (5, 5), 0)  # Simulate processing
                roi_times.append(time.time() - start)
            
            results['roi_processing'] = {
                'avg_full_time': np.mean(full_times),
                'avg_roi_time': np.mean(roi_times),
                'roi_speedup': np.mean(full_times) / np.mean(roi_times)
            }
            
            print(f"   Full Image Time: {np.mean(full_times)*1000:.2f}ms")
            print(f"   ROI Time: {np.mean(roi_times)*1000:.2f}ms")
            print(f"   ROI Speedup: {results['roi_processing']['roi_speedup']:.2f}x")
            
            # Test 3: Frame Skipping Optimization
            print("\n‚è≠Ô∏è Test 3: Frame Skipping Optimization")
            
            verifier = OptimizedLivenessVerifier()
            
            # Test different frame skip intervals
            skip_intervals = [1, 2, 3, 5]
            skip_results = {}
            
            for skip in skip_intervals:
                verifier.landmark_detector.frame_skip = skip
                
                processing_times = []
                for i, test_data in enumerate(self.test_images[:20]):
                    if i % skip == 0:  # Only process every skip frames
                        start = time.time()
                        _ = verifier.process_frame_optimized(test_data['image'])
                        processing_times.append(time.time() - start)
                
                skip_results[skip] = {
                    'avg_time': np.mean(processing_times),
                    'effective_fps': 1.0 / (np.mean(processing_times) * skip),
                    'frames_processed': len(processing_times)
                }
                
                print(f"   Skip {skip}: {np.mean(processing_times)*1000:.1f}ms, Effective FPS: {skip_results[skip]['effective_fps']:.1f}")
            
            results['frame_skipping'] = skip_results
            
            # Test 4: Threaded Processing
            print("\nüßµ Test 4: Threaded Processing Performance")
            
            try:
                threaded_processor = ThreadedLivenessProcessor(max_workers=2)
                
                # Sequential processing
                sequential_times = []
                for test_data in self.test_images[:10]:
                    start = time.time()
                    _ = verifier.process_frame_optimized(test_data['image'])
                    sequential_times.append(time.time() - start)
                
                # Threaded processing
                threaded_times = []
                for test_data in self.test_images[:10]:
                    start = time.time()
                    future = threaded_processor.process_frame_async(test_data['image'])
                    result = threaded_processor.get_result(timeout=1.0)
                    if result:
                        threaded_times.append(time.time() - start)
                
                results['threaded_processing'] = {
                    'sequential_avg_time': np.mean(sequential_times),
                    'threaded_avg_time': np.mean(threaded_times) if threaded_times else 0,
                    'threading_speedup': (np.mean(sequential_times) / np.mean(threaded_times)) if threaded_times else 0
                }
                
                print(f"   Sequential: {np.mean(sequential_times)*1000:.1f}ms")
                if threaded_times:
                    print(f"   Threaded: {np.mean(threaded_times)*1000:.1f}ms")
                    print(f"   Threading Speedup: {results['threaded_processing']['threading_speedup']:.2f}x")
                else:
                    print(f"   ‚ùå Threaded processing failed")
                
                threaded_processor.cleanup()
                
            except Exception as e:
                results['threaded_processing'] = {'error': str(e)}
                print(f"   ‚ùå Threaded processing test failed: {e}")
                
        except Exception as e:
            print(f"‚ùå Processing pipeline optimization testing failed: {e}")
            results['error'] = str(e)
        
        return results
    
    def test_resource_management(self):
        """Test resource management optimization features"""
        print("\n" + "="*60)
        print("üíæ TESTING RESOURCE MANAGEMENT")
        print("="*60)
        
        results = {}
        
        try:
            # Test 1: Memory Management
            print("\nüß† Test 1: Memory Management")
            
            memory_manager = MemoryManager(cleanup_interval=10, max_memory_mb=100)
            
            # Monitor memory before
            initial_memory = memory_manager.check_memory_usage()
            
            # Create memory load
            large_arrays = []
            for i in range(50):
                large_arrays.append(np.random.randint(0, 255, (1000, 1000, 3), dtype=np.uint8))
                if memory_manager.should_cleanup():
                    memory_manager.cleanup()
                    break
            
            # Monitor memory after cleanup
            final_memory = memory_manager.check_memory_usage()
            
            results['memory_management'] = {
                'initial_memory_mb': initial_memory,
                'final_memory_mb': final_memory,
                'cleanup_triggered': len(large_arrays) < 50,
                'memory_saved_mb': max(0, initial_memory - final_memory)
            }
            
            print(f"   Initial Memory: {initial_memory:.1f} MB")
            print(f"   Final Memory: {final_memory:.1f} MB")
            print(f"   Cleanup Triggered: {results['memory_management']['cleanup_triggered']}")
            
            # Test 2: CPU Usage Monitoring
            print("\n‚öôÔ∏è Test 2: CPU Usage Monitoring")
            
            cpu_readings = []
            for _ in range(10):
                cpu_percent = psutil.cpu_percent(interval=0.1)
                cpu_readings.append(cpu_percent)
            
            results['cpu_monitoring'] = {
                'avg_cpu_usage': np.mean(cpu_readings),
                'max_cpu_usage': np.max(cpu_readings),
                'cpu_readings': cpu_readings
            }
            
            print(f"   Average CPU Usage: {np.mean(cpu_readings):.1f}%")
            print(f"   Max CPU Usage: {np.max(cpu_readings):.1f}%")
            
            # Test 3: GPU Availability Check
            print("\nüéÆ Test 3: GPU Availability Check")
            
            gpu_available = False
            gpu_info = {}
            
            try:
                import torch
                gpu_available = torch.cuda.is_available()
                if gpu_available:
                    gpu_info = {
                        'device_count': torch.cuda.device_count(),
                        'device_name': torch.cuda.get_device_name(0),
                        'memory_allocated': torch.cuda.memory_allocated() / 1024**2,  # MB
                        'memory_cached': torch.cuda.memory_reserved() / 1024**2  # MB
                    }
            except ImportError:
                gpu_info['error'] = 'PyTorch not available'
            
            results['gpu_availability'] = {
                'available': gpu_available,
                'info': gpu_info
            }
            
            if gpu_available:
                print(f"   ‚úÖ GPU Available: {gpu_info.get('device_name', 'Unknown')}")
                print(f"   GPU Memory: {gpu_info.get('memory_allocated', 0):.1f} MB allocated")
            else:
                print(f"   ‚ùå GPU Not Available")
            
            # Test 4: Dynamic FPS Adjustment Simulation
            print("\nüìπ Test 4: Dynamic FPS Adjustment Simulation")
            
            # Simulate different system loads and FPS adjustments
            system_loads = [30, 50, 70, 85, 95]  # CPU percentages
            fps_adjustments = []
            
            for load in system_loads:
                # Simulate FPS adjustment logic
                if load > 80:
                    new_fps = max(10, 30 * 0.7)  # Reduce FPS
                elif load < 50:
                    new_fps = min(30, 30 * 1.1)  # Increase FPS
                else:
                    new_fps = 30  # Keep current
                
                fps_adjustments.append({
                    'cpu_load': load,
                    'adjusted_fps': new_fps,
                    'adjustment_factor': new_fps / 30
                })
            
            results['dynamic_fps'] = {
                'adjustments': fps_adjustments,
                'adaptive_behavior': True
            }
            
            print(f"   Dynamic FPS adjustments tested:")
            for adj in fps_adjustments:
                print(f"     CPU {adj['cpu_load']}% ‚Üí FPS {adj['adjusted_fps']:.1f} (factor: {adj['adjustment_factor']:.2f})")
                
        except Exception as e:
            print(f"‚ùå Resource management testing failed: {e}")
            results['error'] = str(e)
        
        return results
    
    def test_accuracy_improvements(self):
        """Test accuracy improvement features"""
        print("\n" + "="*60)
        print("üéØ TESTING ACCURACY IMPROVEMENTS")
        print("="*60)
        
        results = {}
        
        try:
            # Test 1: Adaptive Thresholds
            print("\nüéöÔ∏è Test 1: Adaptive Thresholds")
            
            if OPTIMIZED_DETECTION_AVAILABLE:
                threshold_manager = AdaptiveThresholdManager(learning_rate=0.1)
                
                # Test with different lighting conditions
                lighting_conditions = [
                    {'brightness': 50, 'contrast': 20, 'name': 'low_light'},
                    {'brightness': 120, 'contrast': 40, 'name': 'normal_light'},
                    {'brightness': 200, 'contrast': 30, 'name': 'bright_light'}
                ]
                
                threshold_adaptations = []
                
                for condition in lighting_conditions:
                    # Simulate environment analysis
                    image = np.ones((224, 224, 3), dtype=np.uint8) * condition['brightness']
                    noise = np.random.normal(0, condition['contrast'], image.shape)
                    image = np.clip(image + noise, 0, 255).astype(np.uint8)
                    
                    # Analyze environment
                    threshold_manager.analyze_environment(image)
                    threshold_manager.update_thresholds()
                    
                    current_threshold = threshold_manager.get_threshold('blink_threshold')
                    
                    threshold_adaptations.append({
                        'condition': condition['name'],
                        'brightness': condition['brightness'],
                        'contrast': condition['contrast'],
                        'adapted_threshold': current_threshold
                    })
                
                results['adaptive_thresholds'] = {
                    'success': True,
                    'adaptations': threshold_adaptations,
                    'base_threshold': threshold_manager.base_thresholds['blink_threshold']
                }
                
                print(f"   ‚úÖ Adaptive thresholds working")
                for adapt in threshold_adaptations:
                    print(f"     {adapt['condition']}: threshold = {adapt['adapted_threshold']:.3f}")
            else:
                results['adaptive_thresholds'] = {'error': 'Optimized detection not available'}
                print(f"   ‚ùå Adaptive thresholds test skipped")
            
            # Test 2: Temporal Consistency
            print("\n‚è±Ô∏è Test 2: Temporal Consistency")
            
            # Simulate temporal consistency checking
            confidence_sequence = [0.6, 0.65, 0.7, 0.68, 0.72, 0.75, 0.73, 0.76, 0.8, 0.78]
            decision_sequence = [c > 0.7 for c in confidence_sequence]
            
            # Calculate consistency metrics
            confidence_variance = np.var(confidence_sequence)
            decision_consistency = 1.0 - np.std([int(d) for d in decision_sequence])
            
            # Apply temporal smoothing
            smoothed_confidences = []
            window_size = 3
            for i in range(len(confidence_sequence)):
                start_idx = max(0, i - window_size + 1)
                window = confidence_sequence[start_idx:i+1]
                smoothed_confidences.append(np.mean(window))
            
            temporal_improvement = np.var(confidence_sequence) - np.var(smoothed_confidences)
            
            results['temporal_consistency'] = {
                'original_variance': confidence_variance,
                'smoothed_variance': np.var(smoothed_confidences),
                'improvement': temporal_improvement,
                'decision_consistency': decision_consistency,
                'smoothing_effective': temporal_improvement > 0
            }
            
            print(f"   Original Variance: {confidence_variance:.4f}")
            print(f"   Smoothed Variance: {np.var(smoothed_confidences):.4f}")
            print(f"   Improvement: {temporal_improvement:.4f}")
            print(f"   ‚úÖ Temporal consistency {'effective' if temporal_improvement > 0 else 'not effective'}")
            
            # Test 3: Data Augmentation (Inference-time)
            print("\nüîÑ Test 3: Inference-time Data Augmentation")
            
            if OPTIMIZED_CNN_AVAILABLE:
                predictor = OptimizedLivenessPredictor()
                test_image = self.test_images[0]['image']
                
                # Original prediction
                original_result = predictor.predict_optimized(test_image)
                
                # Augmented predictions
                augmented_results = []
                augmentations = [
                    lambda img: cv2.flip(img, 1),  # Horizontal flip
                    lambda img: cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE),  # Rotation
                    lambda img: cv2.GaussianBlur(img, (3, 3), 0),  # Slight blur
                ]
                
                for aug_func in augmentations:
                    try:
                        aug_image = aug_func(test_image.copy())
                        aug_result = predictor.predict_optimized(aug_image)
                        augmented_results.append(aug_result['confidence'])
                    except Exception as e:
                        print(f"     Augmentation failed: {e}")
                
                # Ensemble prediction from augmentations
                if augmented_results:
                    ensemble_confidence = np.mean([original_result['confidence']] + augmented_results)
                    confidence_std = np.std([original_result['confidence']] + augmented_results)
                else:
                    ensemble_confidence = original_result['confidence']
                    confidence_std = 0
                
                results['data_augmentation'] = {
                    'original_confidence': original_result['confidence'],
                    'augmented_confidences': augmented_results,
                    'ensemble_confidence': ensemble_confidence,
                    'confidence_std': confidence_std,
                    'augmentations_successful': len(augmented_results)
                }
                
                print(f"   Original Confidence: {original_result['confidence']:.3f}")
                print(f"   Ensemble Confidence: {ensemble_confidence:.3f}")
                print(f"   Confidence Std: {confidence_std:.3f}")
                print(f"   ‚úÖ {len(augmented_results)} augmentations successful")
            else:
                results['data_augmentation'] = {'error': 'Optimized CNN not available'}
                print(f"   ‚ùå Data augmentation test skipped")
            
        except Exception as e:
            print(f"‚ùå Accuracy improvements testing failed: {e}")
            results['error'] = str(e)
        
        return results
    
    def test_integration_performance(self):
        """Test integrated system performance"""
        print("\n" + "="*60)
        print("üèóÔ∏è TESTING INTEGRATION PERFORMANCE")
        print("="*60)
        
        results = {}
        
        try:
            # Test 1: Web Application Integration
            print("\nüåê Test 1: Web Application Integration")
            
            if WEB_OPTIMIZATION_AVAILABLE:
                optimization_manager = SystemOptimizationManager()
                optimization_manager.initialize_optimized_models()
                
                frame_processor = OptimizedFrameProcessor()
                
                # Test processing pipeline with multiple frames
                processing_times = []
                optimization_stats = []
                
                for i, test_data in enumerate(self.test_images[:20]):
                    start = time.time()
                    result = frame_processor.process_frame(test_data['image'], f"session_{i}")
                    processing_time = time.time() - start
                    
                    processing_times.append(processing_time)
                    if 'optimization_stats' in result:
                        optimization_stats.append(result['optimization_stats'])
                
                # Get performance statistics
                performance_stats = frame_processor.get_performance_stats()
                
                results['web_integration'] = {
                    'avg_processing_time': np.mean(processing_times),
                    'max_processing_time': np.max(processing_times),
                    'min_processing_time': np.min(processing_times),
                    'estimated_fps': 1.0 / np.mean(processing_times),
                    'performance_stats': performance_stats,
                    'optimization_features_active': len(optimization_stats)
                }
                
                print(f"   Average Processing Time: {np.mean(processing_times)*1000:.1f}ms")
                print(f"   Estimated FPS: {1.0/np.mean(processing_times):.1f}")
                print(f"   Optimization Features Active: {len(optimization_stats)}")
                
                frame_processor.cleanup()
            else:
                results['web_integration'] = {'error': 'Web optimization not available'}
                print(f"   ‚ùå Web integration test skipped")
            
            # Test 2: Memory Usage Over Time
            print("\nüìà Test 2: Memory Usage Over Time")
            
            memory_readings = []
            processing_times = []
            
            for i in range(50):
                # Monitor memory
                memory_mb = psutil.virtual_memory().used / 1024 / 1024
                memory_readings.append(memory_mb)
                
                # Process frame
                start = time.time()
                # Simulate processing
                if OPTIMIZED_CNN_AVAILABLE:
                    predictor = OptimizedLivenessPredictor()
                    _ = predictor.predict_optimized(self.test_images[i % len(self.test_images)]['image'])
                processing_times.append(time.time() - start)
                
                # Cleanup every 10 iterations
                if i % 10 == 0:
                    gc.collect()
            
            memory_growth = memory_readings[-1] - memory_readings[0]
            avg_memory = np.mean(memory_readings)
            
            results['memory_over_time'] = {
                'initial_memory': memory_readings[0],
                'final_memory': memory_readings[-1],
                'memory_growth': memory_growth,
                'avg_memory': avg_memory,
                'max_memory': np.max(memory_readings),
                'avg_processing_time': np.mean(processing_times)
            }
            
            print(f"   Initial Memory: {memory_readings[0]:.1f} MB")
            print(f"   Final Memory: {memory_readings[-1]:.1f} MB")
            print(f"   Memory Growth: {memory_growth:.1f} MB")
            print(f"   Average Memory: {avg_memory:.1f} MB")
            
            # Test 3: Stress Test
            print("\nüí™ Test 3: System Stress Test")
            
            stress_test_duration = 10  # seconds
            stress_start_time = time.time()
            stress_frame_count = 0
            stress_processing_times = []
            stress_memory_readings = []
            
            while time.time() - stress_start_time < stress_test_duration:
                # Process frame
                test_image = self.test_images[stress_frame_count % len(self.test_images)]['image']
                
                start = time.time()
                if OPTIMIZED_CNN_AVAILABLE:
                    predictor = OptimizedLivenessPredictor()
                    _ = predictor.predict_optimized(test_image)
                stress_processing_times.append(time.time() - start)
                
                # Monitor memory
                memory_mb = psutil.virtual_memory().used / 1024 / 1024
                stress_memory_readings.append(memory_mb)
                
                stress_frame_count += 1
                
                # Small delay to prevent overwhelming
                time.sleep(0.01)
            
            actual_duration = time.time() - stress_start_time
            actual_fps = stress_frame_count / actual_duration
            
            results['stress_test'] = {
                'duration': actual_duration,
                'frames_processed': stress_frame_count,
                'actual_fps': actual_fps,
                'avg_processing_time': np.mean(stress_processing_times),
                'max_processing_time': np.max(stress_processing_times),
                'memory_stability': np.std(stress_memory_readings),
                'performance_degradation': np.polyfit(range(len(stress_processing_times)), stress_processing_times, 1)[0]
            }
            
            print(f"   Duration: {actual_duration:.1f}s")
            print(f"   Frames Processed: {stress_frame_count}")
            print(f"   Actual FPS: {actual_fps:.1f}")
            print(f"   Memory Stability (std): {np.std(stress_memory_readings):.1f} MB")
            
        except Exception as e:
            print(f"‚ùå Integration performance testing failed: {e}")
            results['error'] = str(e)
        
        return results
    
    def run_comprehensive_test(self):
        """Run all optimization tests"""
        print("üß™ STARTING COMPREHENSIVE STEP 6 OPTIMIZATION TESTING")
        print("="*80)
        
        # Record start time and initial system state
        test_start = time.time()
        initial_memory = psutil.virtual_memory().used / 1024 / 1024
        
        # Run all tests
        self.test_results['model_optimization'] = self.test_model_optimization()
        self.test_results['processing_pipeline_optimization'] = self.test_processing_pipeline_optimization()
        self.test_results['resource_management'] = self.test_resource_management()
        self.test_results['accuracy_improvements'] = self.test_accuracy_improvements()
        self.test_results['integration_performance'] = self.test_integration_performance()
        
        # Calculate final statistics
        total_duration = time.time() - test_start
        final_memory = psutil.virtual_memory().used / 1024 / 1024
        memory_usage = final_memory - initial_memory
        
        # Generate summary
        summary = self._generate_test_summary(total_duration, memory_usage)
        self.test_results['summary'] = summary
        
        print("\n" + "="*80)
        print("üìä TEST SUMMARY")
        print("="*80)
        print(f"Total Test Duration: {total_duration:.2f} seconds")
        print(f"Memory Usage: {memory_usage:.1f} MB")
        print(f"Tests Completed: {len(self.test_results) - 1}")  # -1 for summary
        
        # Print optimization features summary
        print(f"\n‚úÖ OPTIMIZATION FEATURES VERIFIED:")
        for category, results in self.test_results.items():
            if category != 'summary' and 'error' not in results:
                print(f"   ‚Ä¢ {category.replace('_', ' ').title()}: PASSED")
            elif category != 'summary':
                print(f"   ‚Ä¢ {category.replace('_', ' ').title()}: FAILED")
        
        return self.test_results
    
    def _generate_test_summary(self, duration, memory_usage):
        """Generate comprehensive test summary"""
        summary = {
            'test_duration': duration,
            'memory_usage': memory_usage,
            'tests_passed': 0,
            'tests_failed': 0,
            'optimization_features_verified': [],
            'performance_improvements': {},
            'recommendations': []
        }
        
        # Count passed/failed tests
        for category, results in self.test_results.items():
            if 'error' not in results:
                summary['tests_passed'] += 1
                summary['optimization_features_verified'].append(category)
            else:
                summary['tests_failed'] += 1
        
        # Extract performance improvements
        if 'model_optimization' in self.test_results:
            model_results = self.test_results['model_optimization']
            if 'performance_comparison' in model_results:
                summary['performance_improvements']['quantization_speedup'] = model_results['performance_comparison'].get('speedup_factor', 0)
            if 'caching_performance' in model_results:
                summary['performance_improvements']['cache_speedup'] = model_results['caching_performance'].get('cache_speedup', 0)
        
        # Generate recommendations
        if summary['tests_failed'] > 0:
            summary['recommendations'].append("Install missing optimization dependencies")
        if memory_usage > 100:
            summary['recommendations'].append("Consider implementing more aggressive memory cleanup")
        if duration > 60:
            summary['recommendations'].append("Optimize test procedures for faster execution")
        
        return summary
    
    def save_results(self, filename="step6_optimization_test_results.json"):
        """Save test results to JSON file"""
        try:
            with open(filename, 'w') as f:
                json.dump(self.test_results, f, indent=2, default=str)
            print(f"üìÅ Test results saved to {filename}")
        except Exception as e:
            print(f"‚ùå Failed to save results: {e}")


def main():
    """Main function to run optimization tests"""
    print("üöÄ STEP 6 OPTIMIZATION TESTING SUITE")
    print("Testing comprehensive system performance optimizations from yangIni.md Step 6")
    print("="*80)
    
    try:
        # Create tester instance
        tester = OptimizationTester()
        
        # Run comprehensive tests
        results = tester.run_comprehensive_test()
        
        # Save results
        tester.save_results()
        
        print("\nüéâ STEP 6 OPTIMIZATION TESTING COMPLETED!")
        print("="*80)
        
        return True
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Testing interrupted by user")
        return False
    except Exception as e:
        print(f"\n‚ùå Testing failed with error: {e}")
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
